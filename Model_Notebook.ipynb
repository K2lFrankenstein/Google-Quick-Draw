{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Specifying the requirement packages with versions necessary for the model."
      ],
      "metadata": {
        "id": "4818vVtxEV-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pip\n",
        "!pip install numpy==1.21.6\n",
        "!pip install scipy==1.7.3\n",
        "!pip install pandas==1.5.2\n",
        "!pip install scikit-learn==1.1.2\n",
        "!pip install tensorflow==2.11.0\n",
        "!pip install h5py==3.7.0\n",
        "!pip install torch==1.12.1\n",
        "!pip install -U pickle5"
      ],
      "metadata": {
        "id": "y27er2VwwolU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | egrep 'matplotlib|numpy|pandas|scikit-learn|tensorflow|torch'"
      ],
      "metadata": {
        "id": "liV0xQG7GpA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7babd3b3-b6d8-4b7a-bf07-2d5ac3f3ab1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib                    3.2.2\n",
            "matplotlib-venn               0.11.7\n",
            "numpy                         1.21.6\n",
            "pandas                        1.5.2\n",
            "pandas-datareader             0.9.0\n",
            "pandas-gbq                    0.17.9\n",
            "pandas-profiling              1.4.1\n",
            "scikit-learn                  1.1.2\n",
            "sklearn-pandas                1.8.0\n",
            "tensorflow                    2.11.0\n",
            "tensorflow-datasets           4.6.0\n",
            "tensorflow-estimator          2.11.0\n",
            "tensorflow-gcs-config         2.9.1\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-io-gcs-filesystem  0.28.0\n",
            "tensorflow-metadata           1.11.0\n",
            "tensorflow-probability        0.17.0\n",
            "torch                         1.12.1+cu113\n",
            "torchaudio                    0.12.1+cu113\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.13.1\n",
            "torchvision                   0.13.1+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "K-p5UtYbEc4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import (Conv2D, Activation, MaxPooling2D, Flatten, Dense)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import layers\n",
        "import pickle\n",
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "metadata": {
        "id": "Ttz_Tq3fEb24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GMubdd8V66q",
        "outputId": "061a4761-31e8-40aa-92c0-2f08f62269c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "K0HSPLkrKQk2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data from pkl file"
      ],
      "metadata": {
        "id": "KLLP5AE6K17L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pkl = open('/content/drive/MyDrive/Copy of train100c5k_v2.pkl', 'rb')\n",
        "im = pickle.load(pkl)"
      ],
      "metadata": {
        "id": "xZTdduauKTfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing the data and creating training testing split"
      ],
      "metadata": {
        "id": "D7EyzDW0Ky09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = im['data'].values\n",
        "lable = im['target'].values\n",
        "\n",
        "# print(lable.shape)\n",
        "\n",
        "data = [x for x in data]\n",
        "data = np.array(data)\n",
        "data = data.reshape(500000,28,28,1)\n",
        "\n",
        "label = LabelBinarizer()\n",
        "lable = label.fit_transform(lable)\n",
        "\n",
        "train_data, test_data, train_lable, test_lable = train_test_split(data, lable, test_size=0.05,random_state=420)\n",
        "\n",
        "# scaleing the data\n",
        "train_data = train_data / 255.0\n",
        "test_data = test_data / 255.0\n",
        "\n",
        "\n",
        "print(\"data shape\",train_data.shape,test_data.shape)\n",
        "print(\"lable shape\",train_lable.shape,test_lable.shape)\n"
      ],
      "metadata": {
        "id": "xwJTTrwJKpGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23aca78c-9066-44cd-ffa3-f64a6f1edefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data shape (475000, 28, 28, 1) (25000, 28, 28, 1)\n",
            "lable shape (475000, 100) (25000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifier Model"
      ],
      "metadata": {
        "id": "GDM9-tKNKLUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Im_classfification:\n",
        "\n",
        "    def construct(width, height, depth, classes):\n",
        "        model = Sequential()\n",
        "        inputShape = (width, height, depth)\n",
        "\n",
        "        if K.image_data_format() == \"channels_first\":\n",
        "            inputShape = (depth, width, height)\n",
        "            print(inputShape)\n",
        "\n",
        "        # first set of convolution net\n",
        "        print(inputShape,\"asdasdsad\")\n",
        "        model.add(Conv2D(32, (5,5), strides=(1, 1),padding=\"valid\", input_shape=inputShape))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "        # second set of convolution net\n",
        "        model.add(Conv2D(50, (5, 5), strides=(1, 1), padding=\"same\"))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "        # third layer of convolution net\n",
        "        model.add(Conv2D(64, (5, 5), strides=(1, 1), padding=\"valid\"))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "        # Fully connect layer\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(512))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(layers.Dropout(0.25))\n",
        "\n",
        "        # reduction the output\n",
        "        model.add(Dense(256))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(layers.Dropout(0.25))\n",
        "\n",
        "        # softmax classifier\n",
        "        model.add(Dense(classes))\n",
        "        model.add(Activation('softmax'))\n",
        "\n",
        "        return model\n"
      ],
      "metadata": {
        "id": "RoNSec5sPpTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compiling the model"
      ],
      "metadata": {
        "id": "kbxA2DJuLl5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"compiling model .......\")\n",
        "model = Im_classfification.construct(28,28,1,100)\n",
        "# model = classifier.construct(28,28,1,100)\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "tHT9XSzILlKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "765858bc-ceaf-4d47-9d97-986578f5fadf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compiling model .......\n",
            "(28, 28, 1) asdasdsad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "GoHH1RSRLqAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"training the network .......\")\n",
        "H = model.fit(train_data, train_lable, batch_size=200, epochs=50, verbose=1, validation_data=(test_data,test_lable))"
      ],
      "metadata": {
        "id": "35rEn-FJLscR",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the Model for further utilization"
      ],
      "metadata": {
        "id": "FlRxlVp1Lvwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"saving the model ........\")\n",
        "model.save(\"image_recogniation.h5\")"
      ],
      "metadata": {
        "id": "Tikn26CTL1Sh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442f8d75-fc37-4c35-fb37-ae663e4bc809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving the model ........\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "BoqeYU_dL5IO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_data, batch_size=180)\n",
        "print(classification_report(test_lable.argmax(axis=1), predictions.argmax(axis=1)))"
      ],
      "metadata": {
        "id": "6eAl-U-2L7Bw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7feee8c7-469f-4bb0-8607-552905b2db1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139/139 [==============================] - 1s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.83      0.72       249\n",
            "           1       0.85      0.88      0.87       258\n",
            "           2       0.70      0.68      0.69       252\n",
            "           3       0.81      0.84      0.83       264\n",
            "           4       0.80      0.75      0.77       248\n",
            "           5       0.70      0.75      0.73       233\n",
            "           6       0.76      0.70      0.73       264\n",
            "           7       0.49      0.33      0.40       238\n",
            "           8       0.76      0.79      0.78       245\n",
            "           9       0.42      0.43      0.43       230\n",
            "          10       0.58      0.59      0.58       252\n",
            "          11       0.57      0.59      0.58       254\n",
            "          12       0.71      0.78      0.74       246\n",
            "          13       0.83      0.81      0.82       239\n",
            "          14       0.87      0.89      0.88       230\n",
            "          15       0.90      0.87      0.89       248\n",
            "          16       0.80      0.83      0.82       244\n",
            "          17       0.30      0.51      0.38       280\n",
            "          18       0.82      0.79      0.80       222\n",
            "          19       0.74      0.57      0.64       263\n",
            "          20       0.68      0.60      0.64       231\n",
            "          21       0.72      0.82      0.77       235\n",
            "          22       0.54      0.56      0.55       238\n",
            "          23       0.71      0.73      0.72       236\n",
            "          24       0.69      0.69      0.69       241\n",
            "          25       0.47      0.35      0.41       251\n",
            "          26       0.67      0.66      0.67       239\n",
            "          27       0.34      0.35      0.34       257\n",
            "          28       0.60      0.45      0.51       233\n",
            "          29       0.65      0.67      0.66       248\n",
            "          30       0.85      0.86      0.85       235\n",
            "          31       0.77      0.79      0.78       258\n",
            "          32       0.82      0.84      0.83       274\n",
            "          33       0.55      0.47      0.50       257\n",
            "          34       0.90      0.78      0.84       250\n",
            "          35       0.86      0.81      0.84       247\n",
            "          36       0.63      0.71      0.67       268\n",
            "          37       0.84      0.87      0.85       243\n",
            "          38       0.78      0.76      0.77       242\n",
            "          39       0.69      0.75      0.72       266\n",
            "          40       0.71      0.83      0.77       244\n",
            "          41       0.93      0.92      0.92       272\n",
            "          42       0.68      0.71      0.69       253\n",
            "          43       0.85      0.78      0.82       275\n",
            "          44       0.83      0.66      0.74       271\n",
            "          45       0.85      0.78      0.81       267\n",
            "          46       0.50      0.38      0.43       221\n",
            "          47       0.60      0.44      0.51       261\n",
            "          48       0.77      0.75      0.76       243\n",
            "          49       0.58      0.62      0.60       243\n",
            "          50       0.49      0.53      0.50       259\n",
            "          51       0.73      0.75      0.74       249\n",
            "          52       0.86      0.83      0.85       242\n",
            "          53       0.85      0.86      0.85       269\n",
            "          54       0.82      0.71      0.76       271\n",
            "          55       0.76      0.67      0.71       244\n",
            "          56       0.82      0.86      0.84       246\n",
            "          57       0.61      0.63      0.62       254\n",
            "          58       0.62      0.56      0.59       242\n",
            "          59       0.75      0.81      0.78       263\n",
            "          60       0.73      0.85      0.78       233\n",
            "          61       0.46      0.68      0.55       250\n",
            "          62       0.65      0.69      0.67       250\n",
            "          63       0.73      0.80      0.77       269\n",
            "          64       0.63      0.69      0.66       269\n",
            "          65       0.79      0.90      0.84       246\n",
            "          66       0.52      0.63      0.57       218\n",
            "          67       0.66      0.70      0.68       244\n",
            "          68       0.73      0.76      0.75       255\n",
            "          69       0.40      0.37      0.39       256\n",
            "          70       0.79      0.79      0.79       230\n",
            "          71       0.64      0.63      0.64       243\n",
            "          72       0.79      0.72      0.75       238\n",
            "          73       0.77      0.83      0.80       250\n",
            "          74       0.86      0.68      0.76       275\n",
            "          75       0.70      0.72      0.71       242\n",
            "          76       0.71      0.74      0.72       254\n",
            "          77       0.79      0.77      0.78       228\n",
            "          78       0.85      0.74      0.79       254\n",
            "          79       0.79      0.91      0.85       261\n",
            "          80       0.65      0.79      0.71       252\n",
            "          81       0.74      0.75      0.75       236\n",
            "          82       0.79      0.76      0.77       242\n",
            "          83       0.70      0.84      0.77       264\n",
            "          84       0.77      0.72      0.74       281\n",
            "          85       0.59      0.58      0.59       248\n",
            "          86       0.85      0.84      0.84       244\n",
            "          87       0.58      0.50      0.54       250\n",
            "          88       0.69      0.71      0.70       236\n",
            "          89       0.68      0.73      0.70       250\n",
            "          90       0.94      0.86      0.89       249\n",
            "          91       0.95      0.90      0.92       255\n",
            "          92       0.60      0.31      0.41       254\n",
            "          93       0.90      0.93      0.91       242\n",
            "          94       0.91      0.79      0.85       265\n",
            "          95       0.73      0.64      0.68       272\n",
            "          96       0.72      0.75      0.73       235\n",
            "          97       0.88      0.87      0.88       234\n",
            "          98       0.96      0.92      0.94       278\n",
            "          99       0.71      0.70      0.71       251\n",
            "\n",
            "    accuracy                           0.71     25000\n",
            "   macro avg       0.72      0.71      0.71     25000\n",
            "weighted avg       0.72      0.71      0.71     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/mini_project.py '/content/drive/MyDrive/Copy of train100c5k_v2.pkl' '/content/test100c5k_nolabel.pkl'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs6xmXQSiOi8",
        "outputId": "3889826b-eb74-46b2-e178-aa645b16aaa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-05 04:31:00.332201: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-05 04:31:06.078179: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-05 04:31:06.079082: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-05 04:31:06.079123: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-12-05 04:31:17.150862: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "3125/3125 [==============================] - 10s 2ms/step\n",
            "100000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Github Quick draw: https://github.com/googlecreativelab/quickdraw-dataset"
      ],
      "metadata": {
        "id": "PUYUm2YYU1rN"
      }
    }
  ]
}